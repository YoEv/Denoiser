defaults:
  - dset: debug
  - _self_
  - override hydra/job_logging: colorlog
  - override hydra/hydra_logging: colorlog

# Dataset related
sample_rate: 16000
segment: 4
stride: 1    # in seconds, how much to stride between training examples
pad: true   # if training sample is too short, pad it

# Dataset Augmentation
remix: false   # remix noise and clean
bandmask: 0.   # drop at most this fraction of freqs in mel scale
shift: 0    # random shift, number of samples
shift_same: false   # shift noise and clean by the same amount
revecho: 0  # add reverb like augment

# Logging and printing, and does not impact training
num_prints: 5
device: cpu
num_workers: 5
verbose: 0
show: 0   # just show the model and its size and exit

# Checkpointing, by default automatically load last checkpoint
checkpoint: true
continue_from: '/Users/evelyneli/Desktop/denoiser/checkpoint.th' # Path the a checkpoint.th file to start from.
                  # this is not used in the name of the experiment!
                  # so use a dummy=something not to mixup experiments.
continue_best: false  # continue from best, not last state if continue_from is set.
continue_pretrained:   # use either dns48, dns64 or master64 to fine tune from pretrained-model
restart: false # Ignore existing checkpoints
checkpoint_file: checkpoint.th
best_file: best.th  # will contain only best model at any point
history_file: history.json
samples_dir: samples
save_again: false  # if true, only load checkpoint and save again, useful to reexport best.th
model_path: null  # 默认值为 null 或指定路径
convtasnet_small: false  # 是否使用小型 ConvTasNet 模型
convtasnet_large: True  # 是否使用大型 ConvTasNet 模型

# Other stuff
seed: 2036
dummy:  # use this if you want twice the same exp, with a different name

# Evaluation stuff
pesq: True # compute pesq?
eval_every: 10  # compute test metrics every so epochs
dry: 0.  # dry/wet knob value at eval
streaming: False  # use streaming evaluation for Demucs

# Optimization related
optim: adam
lr: 3e-4
beta2: 0.999
loss: l1
stft_loss: False
stft_sc_factor: .5
stft_mag_factor: .5
epochs: 1
batch_size: 16

# Models
model: ConvTasNet
ConvTasNet:
  N: 8               # Encoder filters数量
  L: 1               # 编码器的卷积核大小（相当于时间步的大小）
  B: 16               # Block中通道数量
  H: 32               # 卷积block中的隐藏层通道数量
  P: 1                # 卷积block中的卷积核大小
  X: 16               # 卷积block的数量
  R: 8               # 重复的block层数
  audio_channels: 1   # 输入音频的通道数（立体声为2）
  norm_type: "gLN"    # 使用全局层归一化
  causal: false       # 非因果结构
  mask_nonlinear: 'relu'  # Mask后用ReLU激活函数
  sample_rate: 16000  # 采样率，与 Demucs 一样
  segment_length: 44100 * 2 * 4  # 音频片段长度，可能需要根据实际情况调整
  frame_length: 400    # STFT窗口大小
  frame_step: 100      # STFT步长

# Experiment launching, distributed
ddp: false
ddp_backend: nccl
rendezvous_file: ./rendezvous

# Internal config, don't set manually
rank:
world_size:

# Hydra config
hydra:
  run:
    dir: ./outputs/exp_${hydra.job.override_dirname}
  job:
    config:
      # configuration for the ${hydra.job.override_dirname} runtime variable
      override_dirname:
        kv_sep: '='
        item_sep: ','
        # Remove all paths, as the / in them would mess up things
        # Remove params that would not impact the training itself
        # Remove all slurm and submit params.
        # This is ugly I know...
        exclude_keys: [
          'hydra.job_logging.handles.file.filename',
          'dset.train', 'dset.valid', 'dset.test', 'dset.noisy_json', 'dset.noisy_dir',
          'num_prints', 'continue_from', 'save_again',
          'device', 'num_workers', 'print_freq', 'restart', 'verbose',
          'log', 'ddp', 'ddp_backend', 'rendezvous_file', 'rank', 'world_size']

  job_logging:
    handlers:
      file:
        class: logging.FileHandler
        mode: w
        formatter: colorlog
        filename: trainer.log
      console:
        class: logging.StreamHandler
        formatter: colorlog
        stream: ext://sys.stderr

  hydra_logging:
    handlers:
      console:
        class: logging.StreamHandler
        formatter: colorlog
        stream: ext://sys.stderr